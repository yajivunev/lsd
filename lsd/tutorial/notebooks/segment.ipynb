{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLsuqADfVjiw"
      },
      "source": [
        "*  Before starting, click \"Runtime\" in the top panel, select \"Change runtime type\" and then choose \"GPU\"\n",
        "\n",
        "*  This tutorial follows the inference tutorial, and is therefore condensed. Check out the inference tutorial (**inference.ipynb**) if there is any confusion throughout\n",
        "\n",
        "*  Try running each cell consecutively to see what is happening before changing things around\n",
        "\n",
        "*  Some cells are collapsed by default, these are generally utility functions or are expanded by defaullt in a previous tutorial. Double click to expand/collapse\n",
        "\n",
        "*  sometimes colab can be slow, if this happens you may need to restart the runtime. also, you generally can only run one session at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Nvia0v8MVtwz"
      },
      "source": [
        "#@title install packages + repos\n",
        "\n",
        "# packages\n",
        "!pip install gunpowder\n",
        "!pip install matplotlib\n",
        "!pip install scikit-image\n",
        "!pip install scipy\n",
        "!pip install torch\n",
        "!pip install zarr\n",
        "\n",
        "# repos\n",
        "!pip install git+https://github.com/funkelab/funlib.learn.torch.git\n",
        "!pip install git+https://github.com/funkey/waterz.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "OLCL0uUsV_pr"
      },
      "source": [
        "#@title import packages\n",
        "\n",
        "import gunpowder as gp\n",
        "import h5py\n",
        "import io\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import requests\n",
        "import torch\n",
        "import waterz\n",
        "import zarr\n",
        "\n",
        "from funlib.learn.torch.models import UNet, ConvPass\n",
        "from gunpowder.torch import Predict\n",
        "from scipy.ndimage import label, measurements\n",
        "from scipy.ndimage.filters import maximum_filter\n",
        "from scipy.ndimage.morphology import distance_transform_edt\n",
        "from skimage.segmentation import watershed\n",
        "\n",
        "%matplotlib inline\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "pjmgcsx6WP7D"
      },
      "source": [
        "#@title utility function to view labels\n",
        "\n",
        "# matplotlib uses a default shader\n",
        "# we need to recolor as unique objects\n",
        "\n",
        "def create_lut(labels):\n",
        "\n",
        "    max_label = np.max(labels)\n",
        "\n",
        "    lut = np.random.randint(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            size=(int(max_label + 1), 3),\n",
        "            dtype=np.uint8)\n",
        "\n",
        "    lut = np.append(\n",
        "            lut,\n",
        "            np.zeros(\n",
        "                (int(max_label + 1), 1),\n",
        "                dtype=np.uint8) + 255,\n",
        "            axis=1)\n",
        "\n",
        "    lut[0] = 0\n",
        "    colored_labels = lut[labels]\n",
        "\n",
        "    return colored_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "7s0kNrV4WVML"
      },
      "source": [
        "#@title utility  function to download / save data as zarr\n",
        "\n",
        "def create_data(\n",
        "    url, \n",
        "    name, \n",
        "    offset, \n",
        "    resolution,\n",
        "    sections=None,\n",
        "    squeeze=True):\n",
        "\n",
        "  in_f = h5py.File(io.BytesIO(requests.get(url).content), 'r')\n",
        "\n",
        "  raw = in_f['volumes/raw']\n",
        "  labels = in_f['volumes/labels/neuron_ids']\n",
        "  \n",
        "  container = zarr.open(name, 'a')\n",
        "\n",
        "  if sections is None:\n",
        "    sections=range(raw.shape[0]-1)\n",
        "\n",
        "  for index, section in enumerate(sections):\n",
        "\n",
        "    print(f'Writing data for section {section}')\n",
        "\n",
        "    raw_slice = raw[section]\n",
        "    labels_slice = labels[section]\n",
        "\n",
        "    if squeeze:\n",
        "      raw_slice = np.squeeze(raw_slice)\n",
        "      labels_slice = np.squeeze(labels_slice)\n",
        "\n",
        "    for ds_name, data in [\n",
        "        ('raw', raw_slice),\n",
        "        ('labels', labels_slice)]:\n",
        "        \n",
        "        container[f'{ds_name}/{index}'] = data\n",
        "        container[f'{ds_name}/{index}'].attrs['offset'] = offset\n",
        "        container[f'{ds_name}/{index}'].attrs['resolution'] = resolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvnwUYHBWZF5"
      },
      "source": [
        "# get first section\n",
        "\n",
        "create_data(\n",
        "    'https://cremi.org/static/data/sample_A_20160501.hdf',\n",
        "    'testing_data.zarr',\n",
        "    offset=[0,0],\n",
        "    resolution=[4,4],\n",
        "    sections=[0],\n",
        "    squeeze=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "okAFte1uWevZ"
      },
      "source": [
        "#@title inference wrapper\n",
        "voxel_size = gp.Coordinate((4, 4))\n",
        "\n",
        "input_shape = gp.Coordinate((164, 164))\n",
        "output_shape = gp.Coordinate((124, 124))\n",
        "\n",
        "input_size = input_shape * voxel_size\n",
        "output_size = output_shape * voxel_size\n",
        "\n",
        "# total roi of image to predict on\n",
        "total_roi = gp.Coordinate((1250,1250))*voxel_size\n",
        "\n",
        "num_fmaps=12\n",
        "\n",
        "class MtlsdModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.unet = UNet(\n",
        "            in_channels=1,\n",
        "            num_fmaps=num_fmaps,\n",
        "            fmap_inc_factor=5,\n",
        "            downsample_factors=[\n",
        "                [2, 2],\n",
        "                [2, 2]],\n",
        "            kernel_size_down=[\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]]],\n",
        "            kernel_size_up=[\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]]])\n",
        "\n",
        "        self.lsd_head = ConvPass(num_fmaps, 6, [[1, 1]], activation='Sigmoid')\n",
        "        self.aff_head = ConvPass(num_fmaps, 2, [[1, 1]], activation='Sigmoid')\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        z = self.unet(input)\n",
        "        lsds = self.lsd_head(z)\n",
        "        affs = self.aff_head(z)\n",
        "\n",
        "        return lsds, affs\n",
        "\n",
        "def predict(\n",
        "    checkpoint,\n",
        "    raw_file,\n",
        "    raw_dataset):\n",
        "  \n",
        "  raw = gp.ArrayKey('RAW')\n",
        "  pred_lsds = gp.ArrayKey('PRED_LSDS')\n",
        "  pred_affs = gp.ArrayKey('PRED_AFFS')\n",
        "\n",
        "  scan_request = gp.BatchRequest()\n",
        "\n",
        "  scan_request.add(raw, input_size)\n",
        "  scan_request.add(pred_lsds, output_size)\n",
        "  scan_request.add(pred_affs, output_size)\n",
        "\n",
        "  context = (input_size - output_size) / 2\n",
        "\n",
        "  source = gp.ZarrSource(\n",
        "              raw_file,\n",
        "          {\n",
        "              raw: raw_dataset\n",
        "          },\n",
        "          {\n",
        "              raw: gp.ArraySpec(interpolatable=True)\n",
        "          })\n",
        "  \n",
        "  with gp.build(source):\n",
        "    total_input_roi = source.spec[raw].roi\n",
        "    total_output_roi = source.spec[raw].roi.grow(-context,-context)\n",
        "\n",
        "  model = MtlsdModel()\n",
        "\n",
        "  # set model to eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # add a predict node\n",
        "  predict = gp.torch.Predict(\n",
        "      model=model,\n",
        "      checkpoint=checkpoint,\n",
        "      inputs = {\n",
        "                'input': raw\n",
        "      },\n",
        "      outputs = {\n",
        "          0: pred_lsds,\n",
        "          1: pred_affs})\n",
        "  \n",
        "  # this will scan in chunks equal to the input/output sizes of the respective arrays\n",
        "  scan = gp.Scan(scan_request)\n",
        "  \n",
        "  pipeline = source\n",
        "  pipeline += gp.Normalize(raw)\n",
        "\n",
        "  # raw shape = h,w\n",
        "\n",
        "  pipeline += gp.Unsqueeze([raw])\n",
        "\n",
        "  # raw shape = c,h,w\n",
        "\n",
        "  pipeline += gp.Stack(1)\n",
        "\n",
        "  # raw shape = b,c,h,w\n",
        "\n",
        "  pipeline += predict\n",
        "  pipeline += scan\n",
        "  pipeline += gp.Squeeze([raw])\n",
        "\n",
        "  # raw shape = c,h,w\n",
        "  # pred_lsds shape = b,c,h,w\n",
        "  # pred_affs shape = b,c,h,w\n",
        "\n",
        "  pipeline += gp.Squeeze([raw, pred_lsds, pred_affs])\n",
        "\n",
        "  # raw shape = h,w\n",
        "  # pred_lsds shape = c,h,w\n",
        "  # pred_affs shape = c,h,w\n",
        "\n",
        "  predict_request = gp.BatchRequest()\n",
        "\n",
        "  # this lets us know to process the full image. we will scan over it until it is done\n",
        "  predict_request.add(raw, total_input_roi.get_end())\n",
        "  predict_request.add(pred_lsds, total_output_roi.get_end())\n",
        "  predict_request.add(pred_affs, total_output_roi.get_end())\n",
        "\n",
        "  with gp.build(pipeline):\n",
        "      batch = pipeline.request_batch(predict_request)\n",
        "\n",
        "  return batch[raw].data, batch[pred_lsds].data, batch[pred_affs].data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch checkpoint\n",
        "!wget https://www.dropbox.com/s/r1u8pvji5lbanyq/model_checkpoint_50000"
      ],
      "metadata": {
        "id": "D9lN7Ua7dK2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmowwZdfWxHl"
      },
      "source": [
        "checkpoint = 'model_checkpoint_50000' \n",
        "raw_file = 'testing_data.zarr'\n",
        "raw_dataset = 'raw/0'\n",
        "\n",
        "raw, pred_lsds, pred_affs = predict(checkpoint, raw_file, raw_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE9a28voWzn6"
      },
      "source": [
        "fig, axes = plt.subplots(\n",
        "            1,\n",
        "            3,\n",
        "            figsize=(20, 6),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "# view predictions (for lsds we will just view the mean offset component)\n",
        "axes[0][0].imshow(raw, cmap='gray')\n",
        "axes[0][1].imshow(np.squeeze(pred_affs[0]), cmap='jet')\n",
        "axes[0][2].imshow(np.squeeze(pred_lsds[0]), cmap='jet')\n",
        "axes[0][2].imshow(np.squeeze(pred_lsds[1]), cmap='jet', alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "X6n9frU5W7rT"
      },
      "source": [
        "#@title watershed wrappers\n",
        "def watershed_from_boundary_distance(\n",
        "        boundary_distances,\n",
        "        boundary_mask,\n",
        "        id_offset=0,\n",
        "        min_seed_distance=10):\n",
        "\n",
        "    max_filtered = maximum_filter(boundary_distances, min_seed_distance)\n",
        "    maxima = max_filtered==boundary_distances\n",
        "    seeds, n = label(maxima)\n",
        "\n",
        "    print(f\"Found {n} fragments\")\n",
        "\n",
        "    if n == 0:\n",
        "        return np.zeros(boundary_distances.shape, dtype=np.uint64), id_offset\n",
        "\n",
        "    seeds[seeds!=0] += id_offset\n",
        "\n",
        "    fragments = watershed(\n",
        "        boundary_distances.max() - boundary_distances,\n",
        "        seeds,\n",
        "        mask=boundary_mask)\n",
        "\n",
        "    ret = (fragments.astype(np.uint64), n + id_offset)\n",
        "\n",
        "    return ret\n",
        "\n",
        "def watershed_from_affinities(\n",
        "        affs,\n",
        "        max_affinity_value=1.0,\n",
        "        id_offset=0,\n",
        "        min_seed_distance=10):\n",
        "\n",
        "    mean_affs = 0.5*(affs[1] + affs[2])\n",
        "\n",
        "    fragments = np.zeros(mean_affs.shape, dtype=np.uint64)\n",
        "  \n",
        "    boundary_mask = mean_affs>0.5*max_affinity_value\n",
        "    boundary_distances = distance_transform_edt(boundary_mask)\n",
        "\n",
        "    ret = watershed_from_boundary_distance(\n",
        "        boundary_distances,\n",
        "        boundary_mask,\n",
        "        id_offset=id_offset,\n",
        "        min_seed_distance=min_seed_distance)\n",
        "\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "0WnGY9MHXApc"
      },
      "source": [
        "#@title segmentation wrapper\n",
        "def get_segmentation(affinities, threshold):\n",
        "\n",
        "    fragments = watershed_from_affinities(affinities)[0]\n",
        "    thresholds = [threshold]\n",
        "\n",
        "    generator = waterz.agglomerate(\n",
        "        affs=affinities.astype(np.float32),\n",
        "        fragments=fragments,\n",
        "        thresholds=thresholds,\n",
        "    )\n",
        "\n",
        "    segmentation = next(generator)\n",
        "\n",
        "    return segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pbplTCgXFfh"
      },
      "source": [
        "# watershed assumes 3d arrays, create fake channel dim (call these watershed affs - ws_affs)\n",
        "ws_affs = np.stack([\n",
        "    np.zeros_like(pred_affs[0]),\n",
        "    pred_affs[0],\n",
        "    pred_affs[1]]\n",
        ")\n",
        "\n",
        "# affs shape: 3, h, w\n",
        "\n",
        "# waterz agglomerate requires 4d affs (c, d, h, w) - add fake z dim\n",
        "ws_affs = np.expand_dims(ws_affs, axis=1)\n",
        "\n",
        "#affs shape: 3, 1, h, w\n",
        "\n",
        "#just test a 0.5 threshold. higher thresholds will merge more, lower thresholds will split more\n",
        "threshold = 0.5\n",
        "\n",
        "segmentation = get_segmentation(ws_affs, threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0TBihU-YuBK"
      },
      "source": [
        "fig, axes = plt.subplots(\n",
        "            1,\n",
        "            4,\n",
        "            figsize=(20, 6),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "# view predictions (for lsds we will just view the mean offset component)\n",
        "axes[0][0].imshow(raw, cmap='gray')\n",
        "axes[0][1].imshow(np.squeeze(pred_affs[0]), cmap='jet')\n",
        "axes[0][2].imshow(np.squeeze(pred_lsds[0]), cmap='jet')\n",
        "axes[0][2].imshow(np.squeeze(pred_lsds[1]), cmap='jet', alpha=0.5)\n",
        "axes[0][3].imshow(create_lut(np.squeeze(segmentation)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}