{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxd06q3vZzlm"
      },
      "source": [
        "*  Before starting, click \"Runtime\" in the top panel, select \"Change runtime type\" and then choose \"GPU\"\n",
        "\n",
        "*  This tutorial follows the mtlsd tutorial, and is therefore condensed. Check out the mtlsd tutorial (**train_mtlsd.ipynb**) if there is any confusion throughout\n",
        "\n",
        "*  Try running each cell consecutively to see what is happening before changing things around\n",
        "\n",
        "*  Some cells are collapsed by default, these are generally utility functions or are expanded by defaullt in a previous tutorial. Double click to expand/collapse\n",
        "\n",
        "*  sometimes colab can be slow, if this happens you may need to restart the runtime. also, you generally can only run one session at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFzbgV1YZ2n0",
        "cellView": "form"
      },
      "source": [
        "#@title install packages + repos\n",
        "\n",
        "# packages\n",
        "!pip install gunpowder\n",
        "!pip install matplotlib\n",
        "!pip install torch\n",
        "!pip install zarr\n",
        "\n",
        "# repos\n",
        "!pip install git+https://github.com/funkelab/funlib.learn.torch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UzsrNvAZ5LF",
        "cellView": "form"
      },
      "source": [
        "#@title import packages\n",
        "\n",
        "import gunpowder as gp\n",
        "import h5py\n",
        "import io\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import requests\n",
        "import torch\n",
        "import zarr\n",
        "\n",
        "from funlib.learn.torch.models import UNet, ConvPass\n",
        "from gunpowder.torch import Predict\n",
        "\n",
        "%matplotlib inline\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6exTbzR9Z_uV",
        "cellView": "form"
      },
      "source": [
        "#@title utility function to view labels\n",
        "\n",
        "# matplotlib uses a default shader\n",
        "# we need to recolor as unique objects\n",
        "\n",
        "def create_lut(labels):\n",
        "\n",
        "    max_label = np.max(labels)\n",
        "\n",
        "    lut = np.random.randint(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            size=(int(max_label + 1), 3),\n",
        "            dtype=np.uint8)\n",
        "\n",
        "    lut = np.append(\n",
        "            lut,\n",
        "            np.zeros(\n",
        "                (int(max_label + 1), 1),\n",
        "                dtype=np.uint8) + 255,\n",
        "            axis=1)\n",
        "\n",
        "    lut[0] = 0\n",
        "    colored_labels = lut[labels]\n",
        "\n",
        "    return colored_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al-0cyZlaC57",
        "cellView": "form"
      },
      "source": [
        "#@title utility  function to download / save data as zarr\n",
        "\n",
        "def create_data(\n",
        "    url, \n",
        "    name, \n",
        "    offset, \n",
        "    resolution,\n",
        "    sections=None,\n",
        "    squeeze=True):\n",
        "\n",
        "  in_f = h5py.File(io.BytesIO(requests.get(url).content), 'r')\n",
        "\n",
        "  raw = in_f['volumes/raw']\n",
        "  labels = in_f['volumes/labels/neuron_ids']\n",
        "  \n",
        "  container = zarr.open(name, 'a')\n",
        "\n",
        "  if sections is None:\n",
        "    sections=range(raw.shape[0]-1)\n",
        "\n",
        "  for index, section in enumerate(sections):\n",
        "\n",
        "    print(f'Writing data for section {section}')\n",
        "\n",
        "    raw_slice = raw[section]\n",
        "    labels_slice = labels[section]\n",
        "\n",
        "    if squeeze:\n",
        "      raw_slice = np.squeeze(raw_slice)\n",
        "      labels_slice = np.squeeze(labels_slice)\n",
        "\n",
        "    for ds_name, data in [\n",
        "        ('raw', raw_slice),\n",
        "        ('labels', labels_slice)]:\n",
        "        \n",
        "        container[f'{ds_name}/{index}'] = data\n",
        "        container[f'{ds_name}/{index}'].attrs['offset'] = offset\n",
        "        container[f'{ds_name}/{index}'].attrs['resolution'] = resolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiLtfH8NaLdm"
      },
      "source": [
        "# fetch a random section\n",
        "\n",
        "create_data(\n",
        "    'https://cremi.org/static/data/sample_A_20160501.hdf',\n",
        "    'testing_data.zarr',\n",
        "    offset=[0,0],\n",
        "    resolution=[4,4],\n",
        "    sections=random.sample(range(0,124),1),\n",
        "    squeeze=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6efMx1KYq_A"
      },
      "source": [
        "voxel_size = gp.Coordinate((4, 4))\n",
        "\n",
        "input_shape = gp.Coordinate((164, 164))\n",
        "output_shape = gp.Coordinate((124, 124))\n",
        "\n",
        "input_size = input_shape * voxel_size\n",
        "output_size = output_shape * voxel_size\n",
        "\n",
        "# total roi of image to predict on\n",
        "total_roi = gp.Coordinate((1250,1250))*voxel_size\n",
        "\n",
        "num_fmaps=12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkxBq8BYchlf",
        "cellView": "form"
      },
      "source": [
        "#@title create mtlsd model\n",
        "\n",
        "class MtlsdModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.unet = UNet(\n",
        "            in_channels=1,\n",
        "            num_fmaps=num_fmaps,\n",
        "            fmap_inc_factor=5,\n",
        "            downsample_factors=[\n",
        "                [2, 2],\n",
        "                [2, 2]],\n",
        "            kernel_size_down=[\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]]],\n",
        "            kernel_size_up=[\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]]])\n",
        "\n",
        "        self.lsd_head = ConvPass(num_fmaps, 6, [[1, 1]], activation='Sigmoid')\n",
        "        self.aff_head = ConvPass(num_fmaps, 2, [[1, 1]], activation='Sigmoid')\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        z = self.unet(input)\n",
        "        lsds = self.lsd_head(z)\n",
        "        affs = self.aff_head(z)\n",
        "\n",
        "        return lsds, affs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3yhJQJRRj4X"
      },
      "source": [
        "def predict(\n",
        "    checkpoint,\n",
        "    raw_file,\n",
        "    raw_dataset):\n",
        "  \n",
        "  raw = gp.ArrayKey('RAW')\n",
        "  pred_lsds = gp.ArrayKey('PRED_LSDS')\n",
        "  pred_affs = gp.ArrayKey('PRED_AFFS')\n",
        "\n",
        "  scan_request = gp.BatchRequest()\n",
        "\n",
        "  scan_request.add(raw, input_size)\n",
        "  scan_request.add(pred_lsds, output_size)\n",
        "  scan_request.add(pred_affs, output_size)\n",
        "\n",
        "  context = (input_size - output_size) / 2\n",
        "\n",
        "  source = gp.ZarrSource(\n",
        "              raw_file,\n",
        "          {\n",
        "              raw: raw_dataset\n",
        "          },\n",
        "          {\n",
        "              raw: gp.ArraySpec(interpolatable=True)\n",
        "          })\n",
        "  \n",
        "  with gp.build(source):\n",
        "    total_input_roi = source.spec[raw].roi\n",
        "    total_output_roi = source.spec[raw].roi.grow(-context,-context)\n",
        "\n",
        "  model = MtlsdModel()\n",
        "\n",
        "  # set model to eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # add a predict node\n",
        "  predict = gp.torch.Predict(\n",
        "      model=model,\n",
        "      checkpoint=checkpoint,\n",
        "      inputs = {\n",
        "                'input': raw\n",
        "      },\n",
        "      outputs = {\n",
        "          0: pred_lsds,\n",
        "          1: pred_affs})\n",
        "  \n",
        "  # this will scan in chunks equal to the input/output sizes of the respective arrays\n",
        "  scan = gp.Scan(scan_request)\n",
        "  \n",
        "  pipeline = source\n",
        "  pipeline += gp.Normalize(raw)\n",
        "\n",
        "  # raw shape = h,w\n",
        "\n",
        "  pipeline += gp.Unsqueeze([raw])\n",
        "\n",
        "  # raw shape = c,h,w\n",
        "\n",
        "  pipeline += gp.Stack(1)\n",
        "\n",
        "  # raw shape = b,c,h,w\n",
        "\n",
        "  pipeline += predict\n",
        "  pipeline += scan\n",
        "  pipeline += gp.Squeeze([raw])\n",
        "\n",
        "  # raw shape = c,h,w\n",
        "  # pred_lsds shape = b,c,h,w\n",
        "  # pred_affs shape = b,c,h,w\n",
        "\n",
        "  pipeline += gp.Squeeze([raw, pred_lsds, pred_affs])\n",
        "\n",
        "  # raw shape = h,w\n",
        "  # pred_lsds shape = c,h,w\n",
        "  # pred_affs shape = c,h,w\n",
        "\n",
        "  predict_request = gp.BatchRequest()\n",
        "\n",
        "  # this lets us know to process the full image. we will scan over it until it is done\n",
        "  predict_request.add(raw, total_input_roi.get_end())\n",
        "  predict_request.add(pred_lsds, total_output_roi.get_end())\n",
        "  predict_request.add(pred_affs, total_output_roi.get_end())\n",
        "\n",
        "  with gp.build(pipeline):\n",
        "      batch = pipeline.request_batch(predict_request)\n",
        "\n",
        "  return batch[raw].data, batch[pred_lsds].data, batch[pred_affs].data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch checkpoint\n",
        "!wget https://www.dropbox.com/s/r1u8pvji5lbanyq/model_checkpoint_50000"
      ],
      "metadata": {
        "id": "YCbEfvEXcBzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYbHmh4dTL3V"
      },
      "source": [
        "checkpoint = 'model_checkpoint_50000' \n",
        "raw_file = 'testing_data.zarr'\n",
        "raw_dataset = 'raw/0'\n",
        "\n",
        "raw, pred_lsds, pred_affs = predict(checkpoint, raw_file, raw_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sqKklgfUx-c"
      },
      "source": [
        "fig, axes = plt.subplots(\n",
        "            1,\n",
        "            3,\n",
        "            figsize=(20, 6),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "# view predictions (for lsds we will just view the mean offset component)\n",
        "axes[0][0].imshow(raw, cmap='gray')\n",
        "axes[0][1].imshow(np.squeeze(pred_affs[0]), cmap='jet')\n",
        "axes[0][2].imshow(np.squeeze(pred_lsds[0]), cmap='jet')\n",
        "axes[0][2].imshow(np.squeeze(pred_lsds[1]), cmap='jet', alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srpG9JSYbL7v"
      },
      "source": [
        "*  see how to generate a segmentation in **segment.ipynb**"
      ]
    }
  ]
}