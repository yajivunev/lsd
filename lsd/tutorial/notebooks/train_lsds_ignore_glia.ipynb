{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*  Before starting, click \"Runtime\" in the top panel, select \"Change runtime type\" and then choose \"GPU\"\n",
        "\n",
        "*  This is a bonus tutorial based off the lsd train tutorial (**train_lsd.ipynb** ) and shows an example for training and learning to predict zero inside glia\n",
        "\n",
        "*  Try running each cell consecutively to see what is happening before changing things around\n",
        "\n",
        "*  Some cells are collapsed by default, these are generally utility functions or are expanded by defaullt in a previous tutorial. Double click to expand/collapse\n",
        "\n",
        "*  sometimes colab can be slow when training, if this happens you may need to restart the runtime. also, you generally can only run one session at a time."
      ],
      "metadata": {
        "id": "4nU2T2ItT3cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install packages + repos\n",
        "\n",
        "# packages\n",
        "!pip install gunpowder\n",
        "!pip install matplotlib\n",
        "!pip install scikit-image\n",
        "!pip install torch\n",
        "!pip install zarr\n",
        "\n",
        "# repos\n",
        "!pip install git+https://github.com/funkelab/funlib.learn.torch.git\n",
        "!pip install git+https://github.com/funkelab/lsd.git"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rOtDdz9pT3wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import packages\n",
        "\n",
        "import gunpowder as gp\n",
        "import h5py\n",
        "import io\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "import torch\n",
        "import zarr\n",
        "\n",
        "from funlib.learn.torch.models import UNet, ConvPass\n",
        "from gunpowder.torch import Train\n",
        "from lsd.train.gp import AddLocalShapeDescriptor\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "K6UqE2SrT7jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title utility function to view labels\n",
        "\n",
        "# matplotlib uses a default shader\n",
        "# we need to recolor as unique objects\n",
        "\n",
        "def create_lut(labels):\n",
        "\n",
        "    max_label = np.max(labels)\n",
        "\n",
        "    lut = np.random.randint(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            size=(int(max_label + 1), 3),\n",
        "            dtype=np.uint8)\n",
        "\n",
        "    lut = np.append(\n",
        "            lut,\n",
        "            np.zeros(\n",
        "                (int(max_label + 1), 1),\n",
        "                dtype=np.uint8) + 255,\n",
        "            axis=1)\n",
        "\n",
        "    lut[0] = 0\n",
        "    colored_labels = lut[labels]\n",
        "\n",
        "    return colored_labels"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IYFrRKQ6T-Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title utility function to mask specific ids, download / save data as zarr\n",
        "\n",
        "def create_data(\n",
        "    url, \n",
        "    name, \n",
        "    offset, \n",
        "    resolution,\n",
        "    mask_ids,\n",
        "    sections=None,\n",
        "    squeeze=True):\n",
        "\n",
        "  in_f = h5py.File(io.BytesIO(requests.get(url).content), 'r')\n",
        "\n",
        "  raw = in_f['volumes/raw']\n",
        "  labels = in_f['volumes/labels/neuron_ids']\n",
        "  \n",
        "  container = zarr.open(name, 'a')\n",
        "\n",
        "  if sections is None:\n",
        "    sections=range(raw.shape[0]-1)\n",
        "\n",
        "  for index, section in enumerate(sections):\n",
        "\n",
        "    print(f'Writing data for section {section}')\n",
        "\n",
        "    raw_slice = raw[section]\n",
        "    labels_slice = labels[section]\n",
        "\n",
        "    # set mask id(s) to zero\n",
        "    labels_slice[np.isin(labels_slice, mask_ids)] = 0\n",
        "\n",
        "    # create labels mask (ones like labels)\n",
        "    labels_mask_slice = np.ones_like(labels_slice).astype(np.uint8)\n",
        "\n",
        "    # create ids mask (1 where ids == true), just to use for random location node\n",
        "    ids_mask_slice = (1 - (labels_slice > 0)).astype(np.uint8)\n",
        "\n",
        "    for ds_name, data in [\n",
        "        ('raw', raw_slice),\n",
        "        ('labels', labels_slice),\n",
        "        ('labels_mask', labels_mask_slice),\n",
        "        ('ids_mask', ids_mask_slice)]:\n",
        "\n",
        "        if squeeze:\n",
        "          data = np.squeeze(data)\n",
        "        \n",
        "        container[f'{ds_name}/{index}'] = data\n",
        "        container[f'{ds_name}/{index}'].attrs['offset'] = offset\n",
        "        container[f'{ds_name}/{index}'].attrs['resolution'] = resolution"
      ],
      "metadata": {
        "id": "azSbQNWFUBOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title utility function to view a batch\n",
        "\n",
        "# matplotlib.pyplot wrapper to view data\n",
        "# default shape should be 2 - 2d data\n",
        "\n",
        "def imshow(\n",
        "        raw=None,\n",
        "        ground_truth=None,\n",
        "        target=None,\n",
        "        prediction=None,\n",
        "        h=None,\n",
        "        shader='jet',\n",
        "        subplot=True,\n",
        "        channel=0,\n",
        "        target_name='target',\n",
        "        prediction_name='prediction'):\n",
        "\n",
        "    rows = 0\n",
        "\n",
        "    if raw is not None:\n",
        "        rows += 1\n",
        "        cols = raw.shape[0] if len(raw.shape) > 2 else 1\n",
        "    if ground_truth is not None:\n",
        "        rows += 1\n",
        "        cols = ground_truth.shape[0] if len(ground_truth.shape) > 2 else 1\n",
        "    if target is not None:\n",
        "        rows += 1\n",
        "        cols = target.shape[0] if len(target.shape) > 2 else 1\n",
        "    if prediction is not None:\n",
        "        rows += 1\n",
        "        cols = prediction.shape[0] if len(prediction.shape) > 2 else 1\n",
        "\n",
        "    if subplot:\n",
        "        fig, axes = plt.subplots(\n",
        "            rows,\n",
        "            cols,\n",
        "            figsize=(10, 4),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "    if h is not None:\n",
        "        fig.subplots_adjust(hspace=h)\n",
        "\n",
        "    def wrapper(data,row,name=\"raw\"):\n",
        "\n",
        "        if subplot:\n",
        "            if len(data.shape) == 2:\n",
        "                if name == 'raw':\n",
        "                    axes[0][0].imshow(data, cmap='gray')\n",
        "                    axes[0][0].set_title(name)\n",
        "                else:\n",
        "                    axes[row][0].imshow(create_lut(data))\n",
        "                    axes[row][0].set_title(name)\n",
        "\n",
        "            elif len(data.shape) == 3:\n",
        "                for i, im in enumerate(data):\n",
        "                    if name == 'raw':\n",
        "                        axes[0][i].imshow(im, cmap='gray')\n",
        "                        axes[0][i].set_title(name)\n",
        "                    else:\n",
        "                        axes[row][i].imshow(create_lut(im))\n",
        "                        axes[row][i].set_title(name)\n",
        "\n",
        "            else:\n",
        "                for i, im in enumerate(data):\n",
        "                    axes[row][i].imshow(im[channel], cmap=shader)\n",
        "                    axes[row][i].set_title(name)\n",
        "\n",
        "\n",
        "        else:\n",
        "            if name == 'raw':\n",
        "                plt.imshow(data, cmap='gray')\n",
        "            if name == 'labels':\n",
        "                plt.imshow(data, alpha=0.5)\n",
        "\n",
        "    row=0 \n",
        "\n",
        "    if raw is not None:\n",
        "        wrapper(raw,row=row)\n",
        "        row += 1\n",
        "    if ground_truth is not None:\n",
        "        wrapper(ground_truth,row=row,name='labels')\n",
        "        row += 1\n",
        "    if target is not None:\n",
        "        wrapper(target,row=row,name=target_name)\n",
        "        row += 1\n",
        "    if prediction is not None:\n",
        "        wrapper(prediction,row=row,name=prediction_name)\n",
        "        row += 1\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pFmJZdumUF1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a dark stringy glia id in sample A. Let's learn to ignore it\n",
        "glia_ids = [20474]\n",
        "\n",
        "create_data(\n",
        "    'https://cremi.org/static/data/sample_A_20160501.hdf',\n",
        "    'training_data.zarr',\n",
        "    offset=[0,0],\n",
        "    resolution=[4,4],\n",
        "    mask_ids=glia_ids)"
      ],
      "metadata": {
        "id": "xv3Q5P9CUIoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view a random 5 sections...\n",
        "\n",
        "fig, axes = plt.subplots(\n",
        "            2,\n",
        "            5,\n",
        "            figsize=(20, 6),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "rand = random.sample(range(0, 124), 5)\n",
        "\n",
        "for i,j in enumerate(rand):\n",
        "\n",
        "  raw = zarr.open('training_data.zarr')[f'raw/{j}'][:]\n",
        "  labels = zarr.open('training_data.zarr')[f'labels/{j}'][:]\n",
        "  ids_mask = zarr.open('training_data.zarr')[f'ids_mask/{j}'][:]\n",
        "\n",
        "  axes[0][i].imshow(create_lut(labels))\n",
        "  axes[1][i].imshow(raw, cmap='gray')\n",
        "  axes[1][i].imshow(ids_mask, alpha=0.5)"
      ],
      "metadata": {
        "id": "7rBOjJWxXUBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voxel_size = gp.Coordinate((4, 4))\n",
        "\n",
        "input_shape = gp.Coordinate((164, 164))\n",
        "output_shape = gp.Coordinate((124, 124))\n",
        "\n",
        "input_size = input_shape * voxel_size\n",
        "output_size = output_shape * voxel_size\n",
        "\n",
        "num_samples=124\n",
        "batch_size=5"
      ],
      "metadata": {
        "id": "X3kAxF9TV1oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weighted mean squared error loss\n",
        "\n",
        "class WeightedMSELoss(torch.nn.MSELoss):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(WeightedMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, prediction, target, weights):\n",
        "\n",
        "        scaled = (weights * (prediction - target) ** 2)\n",
        "\n",
        "        if len(torch.nonzero(scaled)) != 0:\n",
        "\n",
        "            mask = torch.masked_select(scaled, torch.gt(weights, 0))\n",
        "            loss = torch.mean(mask)\n",
        "\n",
        "        else:\n",
        "            loss = torch.mean(scaled)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "pUIWqCJXWGC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    iterations,\n",
        "    batch_size,\n",
        "    show_every,\n",
        "    show_gt=True,\n",
        "    show_pred=False,\n",
        "    channels={'offset in y': 0}):\n",
        "\n",
        "    raw = gp.ArrayKey('RAW')\n",
        "    labels = gp.ArrayKey('LABELS')\n",
        "    labels_mask = gp.ArrayKey('LABELS_MASK')\n",
        "    ids_mask = gp.ArrayKey('IDS_MASK')\n",
        "    gt_lsds = gp.ArrayKey('GT_LSDS')\n",
        "    pred_lsds = gp.ArrayKey('PRED_LSDS')\n",
        "\n",
        "    num_samples = 124\n",
        "    num_fmaps = 12\n",
        "    \n",
        "    ds_fact = [(2,2),(2,2)]\n",
        "    num_levels = len(ds_fact) + 1\n",
        "    ksd = [[(3,3), (3,3)]]*num_levels\n",
        "    ksu = [[(3,3), (3,3)]]*(num_levels - 1)\n",
        "\n",
        "    # create unet\n",
        "    unet = UNet(\n",
        "      in_channels=1,\n",
        "      num_fmaps=num_fmaps,\n",
        "      fmap_inc_factor=5,\n",
        "      downsample_factors=ds_fact,\n",
        "      kernel_size_down=ksd,\n",
        "      kernel_size_up=ksu,\n",
        "      constant_upsample=True)\n",
        "\n",
        "    model = torch.nn.Sequential(\n",
        "        unet,\n",
        "        ConvPass(num_fmaps, 6, [[1, 1]], activation='Sigmoid'))\n",
        "    \n",
        "    loss = WeightedMSELoss()\n",
        "    optimizer = torch.optim.Adam(lr=0.5e-4, params=model.parameters())\n",
        "\n",
        "    request = gp.BatchRequest()\n",
        "    request.add(raw, input_size)\n",
        "    request.add(labels, output_size)\n",
        "    request.add(labels_mask, output_size)\n",
        "    request.add(ids_mask, output_size)\n",
        "    request.add(gt_lsds, output_size)\n",
        "    request.add(pred_lsds, output_size)\n",
        "\n",
        "    sources = tuple(\n",
        "        gp.ZarrSource(\n",
        "            'training_data.zarr',  \n",
        "            {\n",
        "                raw: f'raw/{i}',\n",
        "                labels: f'labels/{i}',\n",
        "                labels_mask: f'labels_mask/{i}',\n",
        "                ids_mask: f'ids_mask/{i}'\n",
        "            },  \n",
        "            {\n",
        "                raw: gp.ArraySpec(interpolatable=True),\n",
        "                labels: gp.ArraySpec(interpolatable=False),\n",
        "                labels_mask: gp.ArraySpec(interpolatable=False),\n",
        "                ids_mask: gp.ArraySpec(interpolatable=False)\n",
        "            }) + \n",
        "            gp.Normalize(raw) +\n",
        "            # just use ids mask for restricting batches\n",
        "            gp.RandomLocation(mask=ids_mask, min_masked=0.05)\n",
        "            for i in range(num_samples)\n",
        "        )\n",
        "\n",
        "    # raw:      (h, w)\n",
        "    # labels:   (h, w)\n",
        "\n",
        "    pipeline = sources\n",
        "\n",
        "    pipeline += gp.RandomProvider()\n",
        "\n",
        "    pipeline += gp.SimpleAugment()\n",
        "\n",
        "    pipeline += gp.IntensityAugment(\n",
        "        raw,\n",
        "        scale_min=0.9,\n",
        "        scale_max=1.1,\n",
        "        shift_min=-0.1,\n",
        "        shift_max=0.1)\n",
        "\n",
        "    pipeline += gp.GrowBoundary(labels)\n",
        "\n",
        "    pipeline += AddLocalShapeDescriptor(\n",
        "        labels,\n",
        "        gt_lsds,\n",
        "        sigma=80,\n",
        "        downsample=2)\n",
        "\n",
        "    pipeline += gp.Unsqueeze([raw, labels_mask])\n",
        "\n",
        "    pipeline += gp.Stack(batch_size)\n",
        "\n",
        "    pipeline += gp.PreCache(num_workers=10)\n",
        "\n",
        "    # use labels mask as weights. We want predictions to go close to zero in these regions\n",
        "    pipeline += Train(\n",
        "        model,\n",
        "        loss,\n",
        "        optimizer,\n",
        "        inputs={\n",
        "            'input': raw\n",
        "        },\n",
        "        outputs={\n",
        "            0: pred_lsds\n",
        "        },\n",
        "        loss_inputs={\n",
        "            0: pred_lsds,\n",
        "            1: gt_lsds,\n",
        "            2: labels_mask\n",
        "        })\n",
        "\n",
        "    with gp.build(pipeline):\n",
        "        progress = tqdm(range(iterations))\n",
        "        for i in progress:\n",
        "            batch = pipeline.request_batch(request)\n",
        "\n",
        "            start = request[labels].roi.get_begin()/voxel_size\n",
        "            end = request[labels].roi.get_end()/voxel_size\n",
        "\n",
        "            if i % show_every == 0:\n",
        "              \n",
        "              imshow(raw=np.squeeze(batch[raw].data[:,:,start[0]:end[0],start[1]:end[1]]))\n",
        "              imshow(ground_truth=batch[labels].data)\n",
        "\n",
        "              for n,c in channels.items():\n",
        "                \n",
        "                if show_gt:\n",
        "                  imshow(target=batch[gt_lsds].data, target_name='gt '+n, channel=c)\n",
        "                if show_pred:\n",
        "                  imshow(prediction=batch[pred_lsds].data, prediction_name='pred '+n, channel=c)\n",
        "\n",
        "            progress.set_description(f'Training iteration {i}') \n",
        "            pass"
      ],
      "metadata": {
        "id": "VQH9HwYkWHVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view a batch of ground truth lsds, no need to show predicted lsds yet\n",
        "\n",
        "channels = {\n",
        "    'offset (y)': 0,\n",
        "    'offset (x)': 1,\n",
        "    'orient (y)': 2,\n",
        "    'orient (x)': 3,\n",
        "    'yx change': 4,\n",
        "    'voxel count': 5\n",
        "}\n",
        "\n",
        "train(iterations=1, batch_size=5, show_every=1, channels=channels)"
      ],
      "metadata": {
        "id": "OKhy59PmX5jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train for ~1k iterations, view every 100th batch\n",
        "# lets just view the mean offset y channel\n",
        "# show the prediction as well as the ground truth\n",
        "# will take longer to converge than affs\n",
        "\n",
        "channels = {'offset (y)': 0}\n",
        "\n",
        "train(iterations=1001, batch_size=5, show_every=100, show_pred=True, channels=channels)"
      ],
      "metadata": {
        "id": "K1saXicFX7_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}